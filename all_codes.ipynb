{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bits croper\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = YOLO(\"./model/best.pt\")\n",
    "\n",
    "def sort_boxes_xyxy(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    sorted_by_y = boxes[boxes[:, 1].argsort()]\n",
    "    row1 = sorted_by_y[:17]\n",
    "    row2 = sorted_by_y[17:]\n",
    "    row1 = row1[row1[:, 0].argsort()]\n",
    "    row2 = row2[row2[:, 0].argsort()]\n",
    "    return np.vstack((row1, row2))\n",
    "\n",
    "\n",
    "os.makedirs(\"./crops\", exist_ok=True)\n",
    "\n",
    "for i in range(1, 106):\n",
    "\n",
    "    image_path = f\"./images/{i}.jpg\"\n",
    "    results = model.predict(image_path, conf=0.45)[0]\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    padding = 0\n",
    "\n",
    "    all_boxes = []\n",
    "    all_confs = []\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf.cpu().numpy())\n",
    "        all_boxes.append([x1, y1, x2, y2])\n",
    "        all_confs.append(conf)\n",
    "\n",
    "    all_boxes = np.array(all_boxes)\n",
    "    all_confs = np.array(all_confs)\n",
    "\n",
    "    # pick top 34 by confidence\n",
    "    keep_idx = np.argsort(-all_confs)[:34]\n",
    "    boxes_34 = all_boxes[keep_idx]\n",
    "\n",
    "    # sort into 2 rows and left→right\n",
    "    sorted_boxes = sort_boxes_xyxy(boxes_34)\n",
    "\n",
    "    # remove boxes that are too close\n",
    "    filtered_boxes = []\n",
    "    last_x = None\n",
    "    for box in sorted_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        if last_x is None:\n",
    "            filtered_boxes.append(box)\n",
    "            last_x = x1\n",
    "        else:\n",
    "            if abs(x1 - last_x) >= 20:\n",
    "                filtered_boxes.append(box)\n",
    "                last_x = x1\n",
    "\n",
    "    filtered_boxes = np.array(filtered_boxes)\n",
    "\n",
    "    # ---- CROP AND SAVE ----\n",
    "    box_id = 1\n",
    "    for (x1, y1, x2, y2) in filtered_boxes:\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "\n",
    "        # apply padding safely\n",
    "        px1 = max(0, x1 - padding)\n",
    "        py1 = max(0, y1 - padding)\n",
    "        px2 = min(img.shape[1], x2 + padding)\n",
    "        py2 = min(img.shape[0], y2 + padding)\n",
    "        margin = 19\n",
    "        crop = img[py1+margin:py2-margin, px1+margin:px2-margin]\n",
    "\n",
    "        out_path = f\"./crops/{i}-{box_id}.jpg\"\n",
    "        cv2.imwrite(out_path, crop)\n",
    "        box_id += 1\n",
    "\n",
    "    print(\"done\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d925c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box drawing code with numbers\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "model = YOLO(\"./model/best.pt\")\n",
    "\n",
    "def sort_boxes_xyxy(boxes):\n",
    "    boxes = np.array(boxes)\n",
    "    sorted_by_y = boxes[boxes[:, 1].argsort()]\n",
    "    row1 = sorted_by_y[:17]\n",
    "    row2 = sorted_by_y[17:]\n",
    "    row1 = row1[row1[:, 0].argsort()]\n",
    "    row2 = row2[row2[:, 0].argsort()]\n",
    "    return np.vstack((row1, row2))\n",
    "\n",
    "a = []\n",
    "for i in range(1, 106):\n",
    "    image_path = f\"./images/{i}.jpg\"\n",
    "    results = model.predict(image_path, conf=0.45)[0]\n",
    "    img = cv2.imread(image_path)\n",
    "    BLUE, THICKNESS, padding = (255, 0, 0), 7, 34\n",
    "    all_boxes = []\n",
    "    all_confs = []\n",
    "\n",
    "    for box in results.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "        conf = float(box.conf.cpu().numpy())\n",
    "        all_boxes.append([x1, y1, x2, y2])\n",
    "        all_confs.append(conf)\n",
    "\n",
    "    all_boxes = np.array(all_boxes)\n",
    "    all_confs = np.array(all_confs)\n",
    "    keep_idx = np.argsort(-all_confs)[:34]\n",
    "    boxes_34 = all_boxes[keep_idx]\n",
    "    sorted_boxes = sort_boxes_xyxy(boxes_34)\n",
    "    filtered_boxes = []\n",
    "    last_x = None\n",
    "\n",
    "    for box in sorted_boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "\n",
    "        if last_x is None:\n",
    "            filtered_boxes.append(box)\n",
    "            last_x = x1\n",
    "        else:\n",
    "            if abs(x1 - last_x) >= 20:\n",
    "                filtered_boxes.append(box)\n",
    "                last_x = x1\n",
    "\n",
    "    filtered_boxes = np.array(filtered_boxes)\n",
    "    box_id = 1\n",
    "\n",
    "    \n",
    "    a.append(len(filtered_boxes))\n",
    "    \n",
    "    for (x1, y1, x2, y2) in filtered_boxes:\n",
    "        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "        cv2.rectangle(img, (x1 + padding, y1 + padding), (x2 - padding, y2 - padding), BLUE, THICKNESS)\n",
    "        cv2.putText(img, str(box_id), (x1 + padding, y1 + padding - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.2, BLUE, 3)\n",
    "        box_id += 1\n",
    "\n",
    "    out_path = f\"./box_with_numbers/{i}.jpg\"\n",
    "    cv2.imwrite(out_path, img)\n",
    "    print(\"done\", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image tester code\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"./model/best.pt\")   # or \"epoch_60.pt\", your choice\n",
    "image_path = \"./images/100.jpg\"\n",
    "results = model.predict(image_path)[0]\n",
    "img = cv2.imread(image_path)\n",
    "BLUE = (255, 0, 0)\n",
    "THICKNESS = 7\n",
    "\n",
    "for box in results.boxes:\n",
    "    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "    cv2.rectangle(\n",
    "        img,\n",
    "        (int(x1), int(y1)),\n",
    "        (int(x2), int(y2)),\n",
    "        BLUE,\n",
    "        THICKNESS\n",
    "    )\n",
    "\n",
    "out_path = \"result.jpg\"\n",
    "cv2.imwrite(out_path, img)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image rotater\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from pillow_heif import register_heif_opener\n",
    "\n",
    "register_heif_opener()\n",
    "\n",
    "folder = r\"D:\\zz train\\images\"\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".heic\")):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            rotated = img.rotate(90, expand=True)\n",
    "            rotated.save(img_path)\n",
    "            print(\"Rotated:\", img_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Skipping:\", img_path, \"| Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d216d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images name renamer\n",
    "\n",
    "import os\n",
    "folder = f\"../zz train/images\"\n",
    "start_number = 40\n",
    "files = os.listdir(folder)\n",
    "image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.heic'))]\n",
    "image_files.sort()\n",
    "current_number = start_number\n",
    "\n",
    "for filename in image_files:\n",
    "    old_path = os.path.join(folder, filename)\n",
    "    new_name = f\"{current_number}.jpg\"\n",
    "    new_path = os.path.join(folder, new_name)\n",
    "    os.rename(old_path, new_path)\n",
    "    current_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984431af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image saturation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_folder = \"./crops/\"\n",
    "output_folder = \"./crops_output/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "lower_red1 = np.array([0, 15, 15])\n",
    "upper_red1 = np.array([25, 255, 255])\n",
    "\n",
    "lower_red2 = np.array([155, 15, 15])\n",
    "upper_red2 = np.array([179, 255, 255])\n",
    "\n",
    "kernel = np.ones((3,3), np.uint8)\n",
    "\n",
    "for img_path in glob.glob(input_folder + \"/*.jpg\"):  # change to jpg if needed\n",
    "    img = cv2.imread(img_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 | mask2\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    s = s.astype(np.float32)\n",
    "    s[mask > 0] *= 4\n",
    "    s = np.clip(s, 0, 255).astype(np.uint8)\n",
    "\n",
    "    hsv_enhanced = cv2.merge([h, s, v])\n",
    "    final_img = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    filename = os.path.basename(img_path)\n",
    "    cv2.imwrite(os.path.join(output_folder, filename), final_img)\n",
    "\n",
    "    print(\"Saved:\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b4affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image saturation with thresholding(THRESH_BINARY_INV)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_folder = \"./crops/\"\n",
    "binary_output_folder = \"./crops_binary_inv/\"\n",
    "\n",
    "os.makedirs(binary_output_folder, exist_ok=True)\n",
    "\n",
    "lower_red1 = np.array([0, 15, 15])\n",
    "upper_red1 = np.array([25, 255, 255])\n",
    "\n",
    "lower_red2 = np.array([155, 15, 15])\n",
    "upper_red2 = np.array([179, 255, 255])\n",
    "\n",
    "kernel = np.ones((13,13), np.uint8)\n",
    "\n",
    "for img_path in glob.glob(input_folder + \"/*.jpg\"):\n",
    "    img = cv2.imread(img_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 | mask2\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    s = s.astype(np.float32)\n",
    "    s[mask > 0] *= 4\n",
    "    s = np.clip(s, 0, 255).astype(np.uint8)\n",
    "\n",
    "    hsv_enhanced = cv2.merge([h, s, v])\n",
    "    final_img = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    filename = os.path.basename(img_path)\n",
    "\n",
    "    gray = cv2.cvtColor(final_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_inv = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "    binary_inv = cv2.resize(binary_inv, (32, 32), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    cv2.imwrite(os.path.join(binary_output_folder, filename), binary_inv)\n",
    "\n",
    "    print(\"Saved:\", filename, \"and binary_inv version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d611b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images sorter\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_c)\n",
    "            )\n",
    "            if in_c != out_c else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out += self.shortcut(x)\n",
    "        return self.relu(out)\n",
    "\n",
    "class StrongCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            ResBlock(1, 32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            ResBlock(32, 64),\n",
    "            nn.MaxPool2d(2),  # becomes 8x8\n",
    "\n",
    "            ResBlock(64, 128),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 12)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = StrongCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"./model/model_epoch_190.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"✔ Model loaded successfully\")\n",
    "\n",
    "input_folder = \"./crops_brigntness_fixed_thresh\"\n",
    "output_root = \"./sorted_digits_2\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "for d in range(12):\n",
    "    os.makedirs(os.path.join(output_root, str(d)), exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(input_folder):\n",
    "    if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, fname)\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = torch.tensor(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img).argmax(dim=1).item()\n",
    "\n",
    "    shutil.copy(path, os.path.join(output_root, str(pred), fname))\n",
    "\n",
    "print(\"\\n✔ All predictions completed and images sorted into folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a56a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image generator with out box but adding noise and augmenting images\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "INPUT_DIR = \"./normal data\"\n",
    "OUTPUT_DIR = \"./augmented\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- AUGMENTATION FUNCTIONS ----------\n",
    "\n",
    "def random_translate(img):\n",
    "    h, w = img.shape\n",
    "    tx = random.randint(-7, 7)\n",
    "    ty = random.randint(-7, 7)\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    return cv2.warpAffine(img, M, (w, h), borderValue=0)\n",
    "\n",
    "def add_noise(img):\n",
    "    choice = random.choice([\"gaussian\", \"saltpepper\", \"none\"])\n",
    "    img = img.copy()\n",
    "\n",
    "    if choice == \"gaussian\":\n",
    "        noise = np.random.normal(0, 20, img.shape).astype(np.int16)\n",
    "        img = np.clip(img.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "    elif choice == \"saltpepper\":\n",
    "        prob = 0.02\n",
    "        rnd = np.random.rand(*img.shape)\n",
    "        img[rnd < prob] = 0\n",
    "        img[rnd > 1 - prob] = 255\n",
    "\n",
    "    return img\n",
    "\n",
    "def random_scale(img):\n",
    "    scale = random.uniform(0.85, 1.15)\n",
    "    resized = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    canvas = np.zeros_like(img)\n",
    "    h, w = img.shape\n",
    "    rh, rw = resized.shape\n",
    "\n",
    "    y = (h - rh) // 2\n",
    "    x = (w - rw) // 2\n",
    "\n",
    "    if y >= 0 and x >= 0:\n",
    "        canvas[y:y+rh, x:x+rw] = resized[:h-y, :w-x]\n",
    "    else:\n",
    "        canvas = cv2.resize(resized, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    return canvas\n",
    "\n",
    "def random_rotate(img):\n",
    "    angle = random.uniform(-10, 10)\n",
    "    h, w = img.shape\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (w, h), borderValue=0)\n",
    "\n",
    "def random_margin_crop(img):\n",
    "    # crop and pad simulated\n",
    "    top = random.randint(0, 3)\n",
    "    bottom = random.randint(0, 3)\n",
    "    left = random.randint(0, 3)\n",
    "    right = random.randint(0, 3)\n",
    "\n",
    "    cropped = img[top:28-bottom, left:28-right]\n",
    "\n",
    "    padded = cv2.copyMakeBorder(\n",
    "        cropped,\n",
    "        top, bottom, left, right,\n",
    "        cv2.BORDER_CONSTANT,\n",
    "        value=0\n",
    "    )\n",
    "    return padded\n",
    "\n",
    "# ---- EXTRA: tiny strokes for empty class ----\n",
    "\n",
    "def random_stray_stroke():\n",
    "    img = np.zeros((28, 28), dtype=np.uint8)\n",
    "\n",
    "    # 70% chance no stroke (empty)\n",
    "    if random.random() < 0.7:\n",
    "        return img\n",
    "\n",
    "    # 30% chance: generate stroke\n",
    "    length = random.randint(3, 9)\n",
    "    thickness = random.randint(1, 3)\n",
    "    angle = random.uniform(-40, 40)  # roughly horizontal\n",
    "\n",
    "    # pick LEFT or RIGHT side\n",
    "    if random.random() < 0.5:\n",
    "        # LEFT SIDE\n",
    "        x1 = random.randint(0, 5)\n",
    "    else:\n",
    "        # RIGHT SIDE\n",
    "        x1 = random.randint(22, 27)\n",
    "\n",
    "    y1 = random.randint(5, 22)  # avoid top/bottom\n",
    "\n",
    "    # compute endpoint from angle + length\n",
    "    dx = int(length * np.cos(np.radians(angle)))\n",
    "    dy = int(length * np.sin(np.radians(angle)))\n",
    "\n",
    "    x2 = x1 + dx\n",
    "    y2 = y1 + dy\n",
    "\n",
    "    # clamp endpoints\n",
    "    x2 = np.clip(x2, 0, 27)\n",
    "    y2 = np.clip(y2, 0, 27)\n",
    "\n",
    "    cv2.line(img, (x1, y1), (x2, y2), color=255, thickness=thickness)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# ---------- MAIN PROCESS ----------\n",
    "\n",
    "for cls in range(0, 12):  # 0–11\n",
    "    in_path = os.path.join(INPUT_DIR, str(cls))\n",
    "    out_path = os.path.join(OUTPUT_DIR, str(cls))\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "    file_list = os.listdir(in_path)\n",
    "\n",
    "    if cls == 11:\n",
    "        # empty class special handling\n",
    "        for i in range(5000):  # generate 5k empty samples\n",
    "            img = random_stray_stroke()\n",
    "            cv2.imwrite(os.path.join(out_path, f\"{i}.png\"), img)\n",
    "        print(\"Generated empty-class augmented images.\")\n",
    "        continue\n",
    "\n",
    "    # normal digit classes 0–10\n",
    "    for fname in file_list:\n",
    "        img = cv2.imread(os.path.join(in_path, fname), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        for k in range(4):  # generate 4 augmented copies per image\n",
    "            aug = img.copy()\n",
    "            aug = random_translate(aug)\n",
    "            aug = random_scale(aug)\n",
    "            aug = random_rotate(aug)\n",
    "            aug = random_margin_crop(aug)\n",
    "            aug = add_noise(aug)\n",
    "\n",
    "            save_name = fname.replace(\".png\", \"\").replace(\".jpg\", \"\")\n",
    "            cv2.imwrite(os.path.join(out_path, f\"{save_name}_aug{k}.png\"), aug)\n",
    "\n",
    "    print(\"Done class:\", cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151d065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing exes data\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "DATASET_DIR = \"./augmented\"   # change if needed\n",
    "KEEP_COUNT = 7000\n",
    "\n",
    "for cls in sorted(os.listdir(DATASET_DIR)):\n",
    "    cls_path = os.path.join(DATASET_DIR, cls)\n",
    "    if not os.path.isdir(cls_path):\n",
    "        continue\n",
    "\n",
    "    # list all image files\n",
    "    files = [f for f in os.listdir(cls_path)\n",
    "             if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    print(f\"Class {cls}: found {len(files)} images\")\n",
    "\n",
    "    if len(files) <= KEEP_COUNT:\n",
    "        print(f\"Skipping class {cls} (only {len(files)}, nothing to delete)\")\n",
    "        continue\n",
    "\n",
    "    # choose 7000 random files to keep\n",
    "    keep_files = set(random.sample(files, KEEP_COUNT))\n",
    "\n",
    "    # delete everything else\n",
    "    deleted = 0\n",
    "    for f in files:\n",
    "        if f not in keep_files:\n",
    "            os.remove(os.path.join(cls_path, f))\n",
    "            deleted += 1\n",
    "\n",
    "    print(f\"Class {cls}: kept {KEEP_COUNT}, deleted {deleted}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ac8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 1, bias=False),\n",
    "                nn.BatchNorm2d(out_c)\n",
    "            )\n",
    "            if in_c != out_c else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out += self.shortcut(x)\n",
    "        return self.relu(out)\n",
    "\n",
    "class StrongCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            ResBlock(1, 32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            ResBlock(32, 64),\n",
    "            nn.MaxPool2d(2),  # becomes 8x8\n",
    "\n",
    "            ResBlock(64, 128),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 8 * 8, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 12)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "model = StrongCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"./model/model_epoch_190.pt\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"✔ Model loaded successfully\")\n",
    "\n",
    "input_folder = \"./crops_binary_inv\"\n",
    "output_root = \"./sorted_digits\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "for d in range(12):\n",
    "    os.makedirs(os.path.join(output_root, str(d)), exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(input_folder):\n",
    "    if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, fname)\n",
    "    \n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    img = torch.tensor(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img).argmax(dim=1).item()\n",
    "\n",
    "    shutil.copy(path, os.path.join(output_root, str(pred), fname))\n",
    "\n",
    "print(\"\\n✔ All predictions completed and images sorted into folders.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bfd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop to thresh images\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "input_folder = \"./crops/\"\n",
    "binary_output_folder = \"./crops_binary_inv/\"\n",
    "\n",
    "os.makedirs(binary_output_folder, exist_ok=True)\n",
    "\n",
    "lower_red1 = np.array([0, 15, 15])\n",
    "upper_red1 = np.array([25, 255, 255])\n",
    "\n",
    "lower_red2 = np.array([155, 15, 15])\n",
    "upper_red2 = np.array([179, 255, 255])\n",
    "\n",
    "kernel = np.ones((1,1), np.uint8)\n",
    "\n",
    "image_path = [\"./crops/25-16.jpg\", \"./crops/25-24.jpg\", \"./crops/25-7.jpg\", \"./crops/26-12.jpg\", \"./crops/26-23.jpg\", \"./crops/30-6.jpg\", \"./crops/66-31.jpg\", \n",
    "              \"./crops/40-16.jpg\", \"./crops/40-29.jpg\", \"./crops/41-2.jpg\", \"./crops/41-6.jpg\", \"./crops/41-19.jpg\", \"./crops/64-29.jpg\", \"./crops/58-1.jpg\"]\n",
    "\n",
    "for img_path in glob.glob(input_folder + \"/*.jpg\"):\n",
    "# for img_path in image_path:\n",
    "    img = cv2.imread(img_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = mask1 | mask2\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    s = s.astype(np.float32)\n",
    "    s[mask > 0] *= 4\n",
    "    s = np.clip(s, 0, 255).astype(np.uint8)\n",
    "\n",
    "    hsv_enhanced = cv2.merge([h, s, v])\n",
    "    final_img = cv2.cvtColor(hsv_enhanced, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    filename = os.path.basename(img_path)\n",
    "\n",
    "    gray = cv2.cvtColor(final_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_inv = cv2.threshold(gray, 120, 255, cv2.THRESH_BINARY_INV)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(binary_inv, kernel, iterations=2)\n",
    "    binary_inv = cv2.resize(binary_inv, (28, 28), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    cv2.imwrite(os.path.join(binary_output_folder, filename), binary_inv)\n",
    "    print(\"Saved:\", filename, \"and binary_inv version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e71107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modal training 5th attempt\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", device)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c)\n",
    "        )\n",
    "        self.shortcut = (\n",
    "            nn.Conv2d(in_c, out_c, 1, bias=False)\n",
    "            if in_c != out_c else nn.Identity()\n",
    "        )\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        return self.relu(out)\n",
    "\n",
    "class StrongCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            ResBlock(1, 32),\n",
    "            nn.MaxPool2d(2),    # 28 -> 14\n",
    "            ResBlock(32, 64),\n",
    "            nn.MaxPool2d(2),    # 14 -> 7\n",
    "            ResBlock(64, 128)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 12)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "model = StrongCNN().to(device)\n",
    "model.load_state_dict(torch.load(\"./model/final_28x28_model.pt\", map_location=device))\n",
    "model.eval()\n",
    "print(\"✔ Model loaded successfully\")\n",
    "\n",
    "input_folder = \"./crops_binary_inv\"\n",
    "output_root  = \"./sorted_digits\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "for d in range(12):\n",
    "    os.makedirs(os.path.join(output_root, str(d)), exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(input_folder):\n",
    "    if not fname.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\")):\n",
    "        continue\n",
    "\n",
    "    path = os.path.join(input_folder, fname)\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img_tensor).argmax(dim=1).item()\n",
    "\n",
    "    dest = os.path.join(output_root, str(pred), fname)\n",
    "    shutil.copy(path, dest)\n",
    "\n",
    "print(\"\\n✔ All images processed & sorted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image to pdf converter\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import os\n",
    "\n",
    "folder_path = \"./pdf_based\"\n",
    "output_pdf = \"output.pdf\"\n",
    "\n",
    "valid_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tiff\"]\n",
    "\n",
    "images = []\n",
    "\n",
    "for file in sorted(os.listdir(folder_path)):\n",
    "    ext = os.path.splitext(file)[1].lower()\n",
    "    if ext in valid_extensions:\n",
    "        img_path = os.path.join(folder_path, file)\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Fix EXIF rotation if present\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "\n",
    "        img = img.convert(\"RGB\")   # required for PDF\n",
    "        images.append(img)\n",
    "\n",
    "if len(images) == 0:\n",
    "    print(\"No valid images found!\")\n",
    "else:\n",
    "    images[0].save(output_pdf, save_all=True, append_images=images[1:])\n",
    "    print(\"PDF created:\", output_pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabels_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
